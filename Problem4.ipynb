{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==> loading dataset\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'cunn'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "tar = 'http://torch7.s3-website-us-east-1.amazonaws.com/data/mnist.t7.tgz'\n",
    "\n",
    "if not paths.dirp('mnist.t7') then\n",
    "   os.execute('wget ' .. tar)\n",
    "   os.execute('tar xvf ' .. paths.basename(tar))\n",
    "end\n",
    "\n",
    "trainFile = 'mnist.t7/train_32x32.t7'\n",
    "testFile = 'mnist.t7/test_32x32.t7'\n",
    "\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "print '==> loading dataset'\n",
    "\n",
    "trainSet = nil\n",
    "testSet = nil\n",
    "train = torch.load(trainFile,'ascii')\n",
    "test = torch.load(testFile,'ascii')\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- select train and test set\n",
    "trainSet = {data = train.data[{ {1,6000}, {}, {} }],\n",
    "            label = train.labels[ { {1, 6000} } ]}\n",
    "testSet = {data = test.data[{ {1,1000}, {}, {} }],\n",
    "           label = test.labels[ { {1, 1000} } ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAAAAABWESUoAAAA+0lEQVQ4jWNgGImAWUhIqK5jvdSy/9/rISIsCEk5NisbgWAGBgaGJ5MCP188CBFlhMsb7uWHsv4lfWV49v4muulCt//+/fv377Ft3z/isD9gTvbfv2e5GbRn4XIhH+Osv1HogkxI7E//PzKkMKGrQAHc+/664VXAoPzx4YIcRnwqAj/8/VsuiU+F7q6/f6dJ41MhEPvn7278Dvn596cDnMOCLqsXYsrCcO0QLs3qU57+/fv31zYc0hJFd//+/fv3pB92aXGnq3///v17LBB7YAqtvv3379+/hwM4sUqbr3n09+/fv19audFloL4IDGRguL75b88HXK4f3AAAdeZegIC2SaMAAAAASUVORK5CYII=",
      "text/plain": [
       "Console does not support images"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 32,
       "width": 32
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "-- sample image\n",
    "require 'image'\n",
    "itorch.image(trainSet.data[1])\n",
    "print(trainSet.label[1]) -- label from '1' to '10', '1' is 0, '10' is 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- normalize data\n",
    "trainSet.data = trainSet.data:cuda():div(255)\n",
    "mean = trainSet.data:mean()\n",
    "trainSet.data = trainSet.data:add(-mean)\n",
    "trainSet.label = trainSet.label:cuda()\n",
    "\n",
    "testSet.data = testSet.data:cuda():div(255)\n",
    "testSet.data = testSet.data:add(-mean)\n",
    "testSet.label = testSet.label:cuda()\n",
    "\n",
    "trsize = trainSet.data:size(1)\n",
    "tesize = testSet.data:size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- cnn structure\n",
    "require 'nn'\n",
    "\n",
    "cnn = nn.Sequential()\n",
    "cnn:add(nn.SpatialConvolution(1, 6, 5, 5)) -- 1 input image channel, 6 output channels, 5x5 convolution kernel\n",
    "cnn:add(nn.ReLU())                       -- non-linearity \n",
    "cnn:add(nn.SpatialMaxPooling(2,2,2,2))     -- A max-pooling operation that looks at 2x2 windows and finds the max.\n",
    "cnn:add(nn.SpatialConvolution(6, 16, 5, 5))\n",
    "cnn:add(nn.ReLU())                       -- non-linearity \n",
    "cnn:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "cnn:add(nn.View(16*5*5))                    -- reshapes from a 3D tensor of 16x5x5 into 1D tensor of 16*5*5\n",
    "cnn:add(nn.Linear(16*5*5, 120))             -- fully connected layer (matrix multiplication between input and weights)\n",
    "cnn:add(nn.ReLU())                       -- non-linearity \n",
    "cnn:add(nn.Linear(120, 84))\n",
    "cnn:add(nn.ReLU())                       -- non-linearity \n",
    "cnn:add(nn.Linear(84, 10))                   -- 10 is the number of outputs of the network (in this case, 10 digits)\n",
    "cnn:add(nn.LogSoftMax())                     -- converts the output to a log-probability. Useful for classification problems\n",
    "cnn = cnn:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- cnn criterion\n",
    "criterion = nn.ClassNLLCriterion() -- a negative log-likelihood criterion for multi-class\n",
    "criterion = criterion:cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- batch gd\n",
    "\n",
    "batchSize = 500\n",
    "batchInd = torch.zeros(batchSize)\n",
    "\n",
    "maxEpoch = 2000\n",
    "\n",
    "tra_loss = torch.zeros(maxEpoch)\n",
    "tes_loss = torch.zeros(maxEpoch)\n",
    "eta = 0.2\n",
    "n = 1\n",
    "\n",
    "for k = 1, maxEpoch do\n",
    "    \n",
    "    -- generate batch index\n",
    "    for i = 1, batchSize do\n",
    "        batchInd[i] = torch.random(1, 6000)\n",
    "    end\n",
    "    \n",
    "    -- define batch set\n",
    "    Batch = { data  = trainSet.data:index(1, batchInd:long()),\n",
    "              label = trainSet.label:index(1, batchInd:long())}\n",
    "    \n",
    "    -- train by batch\n",
    "    cnn:zeroGradParameters() -- zero gradient parameters\n",
    "    local outputs = cnn:forward(Batch.data) -- forward\n",
    "    local loss = criterion:forward(outputs, Batch.label) -- calculate loss\n",
    "    local dloss_doutputs = criterion:backward(outputs, Batch.label)\n",
    "    cnn:backward(Batch.data, dloss_doutputs)\n",
    "    tra_loss[n] = loss -- store train loss\n",
    "    cnn:updateParameters(eta) \n",
    "\n",
    "    -- test current network\n",
    "    pred = cnn:forward(testSet.data) \n",
    "    test_loss = criterion:forward(pred, testSet.label)\n",
    "    tes_loss[n] = test_loss -- store test loss\n",
    "\n",
    "    n = n + 1 \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'gnuplot'\n",
    "\n",
    "gnuplot.pngfigure('p4loss1.png')\n",
    "gnuplot.plot({'train loss', tra_loss, '-'},\n",
    "             {'test loss', tes_loss, '-'})\n",
    "gnuplot.plotflush()\n",
    "gnuplot.grid(true)\n",
    "gnuplot.title('train.loss.cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![p4loss1.png](p4loss1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "962\t96.2 % \t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- display performance by right classification\n",
    "correct = 0\n",
    "for i=1,1000 do\n",
    "    local groundtruth = testSet.label[i]\n",
    "    local prediction = cnn:forward(testSet.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "\n",
    "print(correct, 100*correct/1000 .. ' % ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[\n",
    "part 2: xor network\n",
    "since we want to determine if two input image have same digits\n",
    "first we forward 2 images to cnn, then get result of two log probability distribution on all classes\n",
    "If two input image have same digits, the distribution are similar, \n",
    "we could use KL divergence to calculate the distance between two outputs from cnn,\n",
    "then train a threshold neuron to classify if two distribution are same\n",
    "--]]\n",
    "\n",
    "-- net1: two parallel cnn\n",
    "-- inputs: two image\n",
    "-- outputs: two log probability distribution\n",
    "net1 = nn.Sequential():cuda()\n",
    "cnn1 = cnn:clone()\n",
    "cnn2 = cnn:clone()\n",
    "cnn_layer = nn.ParallelTable()\n",
    "cnn_layer:add(cnn1)\n",
    "cnn_layer:add(cnn2)\n",
    "net1:add(cnn_layer)\n",
    "\n",
    "-- xor: inputs are KLdist of two probability distribution\n",
    "-- output: probability of two distribution are same\n",
    "xor = nn.Sequential():cuda()\n",
    "xor:add(nn.Linear(1, 1))\n",
    "xor:add(nn.Sigmoid())\n",
    "\n",
    "-- xor network criterion\n",
    "xor_criterion = nn.MSECriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- split whole data set by their class number\n",
    "-- return a 10 class table\n",
    "function SetClass(Set)\n",
    "    local Class = {}\n",
    "    for i = 1, 10 do\n",
    "        local ind = Set.label:eq(i):nonzero():long():view(-1)\n",
    "        local c = {data  = Set.data:index(1, ind),\n",
    "                   label = Set.label:index(1, ind)}\n",
    "        table.insert(Class, c)\n",
    "    end\n",
    "    \n",
    "    return Class\n",
    "end    \n",
    "\n",
    "-- split both train and test\n",
    "traClass = SetClass(trainSet)\n",
    "tesClass = SetClass(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- generate batch Data to train xor net\n",
    "-- to train xor we need the data set of two images are balance\n",
    "-- e.g.: \n",
    "--    now we need a data set with a bunch of two images, \n",
    "--    and their label is 1 if they have same digits, otherwise the label is 0\n",
    "--    to train a network, we need data of label 1 and data of label 0 are roughly equal\n",
    "--\n",
    "\n",
    "function BatchData(k, Class)\n",
    "    \n",
    "    local cInd = torch.random(1, 10) -- randomly select a class number from 1 to 10\n",
    "    local dInd1 = torch.random(1, Class[cInd].label:size(1)) -- randomly select an instance from that class\n",
    "    local d1 = Class[cInd].data[dInd1] -- get that data\n",
    "    local l1 = Class[cInd].label[dInd1] -- get that class number\n",
    "    \n",
    "    -- if k is even\n",
    "    -- we randomly select a class number from 1 to 10\n",
    "    -- else we keep using previous class number\n",
    "    if k % 2 == 0 then \n",
    "        cInd = torch.random(1, 10)\n",
    "    end\n",
    "    \n",
    "    \n",
    "    local dInd2 = torch.random(1, Class[cInd].label:size(1)) -- randomly select an instance from that class\n",
    "    local d2 = Class[cInd].data[dInd2] -- get that data\n",
    "    local l2 = Class[cInd].label[dInd2] -- get that label\n",
    "\n",
    "    \n",
    "    -- if two class number are same, label is 1, otherwise 0\n",
    "    if l1 == l2 then\n",
    "        xor_l = torch.Tensor{1}\n",
    "    else\n",
    "        xor_l = torch.Tensor{0}\n",
    "    end\n",
    "\n",
    "    local xor_d = {d1, d2}\n",
    "    batchd = {data = xor_d, label = xor_l}\n",
    "    return batchd\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- calculate KL distance from two loglikelihood distribution\n",
    "-- if two distribution are similar, the output is near 0, otherwise the distance is large\n",
    "KL = nn.DistKLDivCriterion():cuda()\n",
    "function KLDist(X)\n",
    "    local x = torch.round(X[1])\n",
    "    local target = torch.round(X[2])\n",
    "\n",
    "    local target = nn.Exp():cuda():forward(target)\n",
    "    local output = torch.Tensor(1)\n",
    "    output[1] = KL:forward(x, target)\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- train xor\n",
    "maxEpoch = 500\n",
    "xor_tra_loss = torch.zeros(maxEpoch)\n",
    "xor_tes_loss = torch.zeros(maxEpoch)\n",
    "\n",
    "tra_bsize = 10\n",
    "tes_bsize = 10\n",
    "\n",
    "eta = 0.01\n",
    "n = 1\n",
    "\n",
    "for k = 1, maxEpoch do \n",
    "    \n",
    "    xor:zeroGradParameters()\n",
    "    tra_bloss = 0\n",
    "    for i = 1, tra_bsize do\n",
    "        local btra_Data = BatchData(k, traClass) -- select data from train set\n",
    "        local inputs = net1:forward(btra_Data.data)\n",
    "        local KLD = KLDist(inputs)\n",
    "        local outputs = xor:forward(KLD) -- train xor classifier\n",
    "        local loss = xor_criterion:forward(outputs, btra_Data.label)\n",
    "        local dloss_doutputs = xor_criterion:backward(outputs, btra_Data.label)\n",
    "        xor:backward(KLD, dloss_doutputs)\n",
    "        tra_bloss = tra_bloss + loss -- update batch train loss\n",
    "    end\n",
    "    xor_tra_loss[n] = tra_bloss/tra_bsize\n",
    "    xor:updateParameters(eta)\n",
    "    \n",
    "    tes_bloss = 0\n",
    "    for i = 1, tes_bsize do\n",
    "        local btes_Data = BatchData(k, tesClass) -- select data from test set\n",
    "        local inputs = net1:forward(btes_Data.data)\n",
    "        local inputs = KLDist(inputs)\n",
    "        local outputs = xor:forward(inputs) -- test xor classifier\n",
    "        local loss = xor_criterion:forward(outputs, btes_Data.label)\n",
    "        tes_bloss = tes_bloss + loss -- update batch test loss\n",
    "    end\n",
    "    xor_tes_loss[n] = tes_bloss/tes_bsize \n",
    "    \n",
    "    n = n + 1\n",
    "    -- print(n)\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'gnuplot'\n",
    "\n",
    "gnuplot.pngfigure('p4loss2.png')\n",
    "gnuplot.plot({'train loss', xor_tra_loss, '-'},\n",
    "             {'test loss', xor_tes_loss, '-'})\n",
    "gnuplot.plotflush()\n",
    "gnuplot.grid(true)\n",
    "gnuplot.title('train.loss.cnn.xor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![p4loss2](p4loss2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9609\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10000\n",
    "require 'image'\n",
    "correctness = 0\n",
    "\n",
    "for i = 1, N do\n",
    "    local btes_Data = BatchData(i, tesClass)\n",
    "    -- itorch.image(btes_Data.data)\n",
    "    local inputs = net1:forward(btes_Data.data)\n",
    "    local inputs = KLDist(inputs)\n",
    "    local outputs = xor:forward(inputs)\n",
    "    if outputs[1] > 0.5 then\n",
    "        pred = 1\n",
    "    else\n",
    "        pred = 0\n",
    "    end\n",
    "    \n",
    "    -- print({btes_Data.label[1], pred})\n",
    "    \n",
    "    if btes_Data.label[1] == pred then\n",
    "        correctness = correctness + 1\n",
    "    end    \n",
    "    \n",
    "end\n",
    "\n",
    "print(correctness / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
